# components of Azure Cosmos DB for NoSQL?
* <ins>Accounts</ins> - fundamental units of distribution and high availability. At the account level, configure the region[s] for your data & set the default consistency level for requests. Accounts also contain the globally unique DNS name used for API requests. 
* <ins>Databases</ins> -  Each account can contain one or more Databases. A database is a logical unit of management for containers
* <ins>Containers</ins> - fundamental unit of scalability. At the container level, provision throughput and Optionally configure an indexing policy or a default time-to-live value. Cosmos will automatically and transparently partition the data in a container.
* <ins>Items</ins> - The NoSQL API for stores individual documents in JSON format as items within the container. Cosmos can provide fast and predictable performance because write operations on JSON documents are atomic.
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/7a66330a-d3b1-4042-bb1c-755f09a092a9)
* Partitioning & Partition Keys
    1. Partitioning involves writing data to servers in a way that optimizes both reads and writes.
    2. Cosmos DB stores data in virtual buckets called logical partitions.
    3. It relies on a partition key to determine which of these buckets to put new data in and where to look for data during a query. 
    * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/02be67b0-4a30-4308-abfc-3cf843ade80a)
    * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/6342c9b4-1171-401e-b902-3681287ab8be)
    4. When choosing a key, following three guidelines.
        1. Find the write balance - Test your partition key to see how it distributes writes. Avoid hotspots and rate limits by achieving even distribution of storage and throughput across logical partitions.
        2. Aim for a single partition query. Look to see how many partitions get hit when you run your most frequent queries. Aoid the cost and latency of involving multiple partitions, by choosing a key that queries a single partition.
        * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/601d6081-3aed-4428-98e7-0095c5ab2113)
        * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/1bc3fe85-b71b-4cc1-8f69-d41ee1e41404)
        3. Understand cross-partition query trade offs. If you do run cross-partition queries for less important workloads every once in a while, it won't impact your overall experience. But if it's more than that, you can use an array of discrete values for the partition keys in your query to target a subset of partitions.
        * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/d3030a58-1b10-4d20-97a3-fcdf76fcaeb4)
        * ![image](https://github.com/mkader/Developer-Tools/assets/3132680/e17ab35d-a944-49b2-98d6-39c81642c3b4)
    5. Every container is required to specify a partition key path. Behind the scenes, Cosmos uses this path to logically partition data using partition key values. For example, consider the following JSON document:
    ``` mark
        {
          "id": "35b5bf7d-5f0e-4209-b7cb-8c5c70c3bb59",
          "deviceDisplayName": "shared-printer",
          "acquiredYear": 2019,
          "department": {
            "name": "information-technology",
            "metadata": {
              "location": "floor-5-unit-27"
            }
          },
          "queuedDocuments": [
            {
              "sender": "user-293749329",
              "sentTime": "2019-07-26T05:12:37",
              "pages": 5,
              "spoolRef": "3f4b759c-3230-4269-a88e-de7620ad91c0"
            },
            {
              "device": {
                "type": "mobile"
              },
              "sentTime": "2019-11-12T13:08:42",
              "spoolRefs": [
                "6a86682c-be5a-4a4a-bacd-96c4d1c7ece6",
                "79e78fe2-93aa-4688-89db-a7278b034aa6"
              ]
            }
          ]
        }
    ```
        1. container specifies a partition key path of /department/name, then the partition key value of this document would be information-technology. Behind the scenes, CosmosL automatically manages the physical resources necessary to support your data workload.

# Understand throughput
* Each container is a unit of scalability for both throughput and storage.
* Containers are partitioned horizontally across compute within an region and distributed across all Regions you configure in your Cosmos account.
* Container-level throughput provisioning
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/06b4c921-2392-4678-86a4-a5d2348fb698)
* Database-level throughput provisioning
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/725fe5be-97b2-4712-9cea-821224df24f7)
* Mixed-throughput provisioning
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/589be45c-f850-459c-a17a-1bd45fd460b5)

# Evaluate throughput requirements
* Request unit(RU)s are a rate-based currency. They are used to make it simple to talk about physical resources like memory, CPU, and IO when performing requests in Cosmos. 
* RUs are used to measure both foreground and background activities.
* Every request consumes a fixed number of RUs, including but not limited to: Reads, Writes, Queries, Stored procedures
* Configuring throughput - create a db or container in CosmosDB, you can provision RUs in an increment of request units per second (or RU/s for short). You cannot provision less than 400 RU/s, and they are provisioned in increments of 100.
* Estimating ad-hoc RU/s consumption - For example, estimate the RU/s required for common db operations such as one RU for a read and six RU/s for a write operation of a 1-KB document in optimal conditions.
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/2ebf2817-7e39-4476-92c8-08b708ddeec5)
* Build a quick table to figure out a rough estimate of your needed RU capacity. Like:
Operation type|Number of requests per second|Number of RU per request|RU/s needed
    Write Single Document|10,000|10|100,000
    -|-|-|-
    Top Query #1|700|100|70,000
    Top Query #2|200|100|20,000
    Top Query #3|100|100|10,000
    Total RU/s|||200,000 RU/s

# Evaluate data storage requirements
* Migrating existing transactional workloads - Use CosmosDB Capacity Calculator to help estimate your app's storage and throughput requirements and translate it to a cost estimate in terms of CosmosDB.
* ![image](https://github.com/mkader/Developer-Tools/assets/3132680/2ce0ab5e-b750-4719-aa49-e19f025b103e)

# Time-to-live (TTL)
* Set the length of time documents live in the db before being automatically purged. It's measured in seconds from the last modification and can be set at the container level with the ability to override on a per-item basis.
* The maximum TTL value is 2147483647.
* Configuring TTL on a container using the <ins>DefaultTimeToLive</ins> property: Does not exist(not automatically expired), -1(not expire by default), n(n seconds after last modified time).
* Examples
    Container.DefaultTimeToLive|Item.ttl|Expiration in seconds
    -|-|-
    1000|null|1000
    1000|-1|This item will never expire
    1000|2000|2000
    Container.DefaultTimeToLive|Item.ttl|Expiration in seconds
    null|null|This item will never expire
    null|-1|This item will never expire
    null|2000|TTL is disabled at the container level. This item will never expire.

# Move data into and out of Azure Cosmos DB for NoSQL
* <ins>Azure Data Factory</ins> is a native service to ETL across sinks and stores in an entirely serverless fashion.
* <ins>Apache Kafka</ins> used to stream events in a distributed manner. Kafka Connect is a tool within their suite to stream data between Kafka and other data systems.
* <ins>Azure Stream Analytics</ins> is a real-time event-processing engine designed to process fast streaming data from multiple sources simultaneously.
* <ins>With Azure Synapse Analytics and Azure Synapse Link for Azure Cosmos DB</ins>, you can create a cloud-native hybrid transactional and analytical processing (HTAP) to run analytics over your data in Azure Cosmos DB for NoSQL. This connection enables integration over your data pipeline on both ends of your data world, Azure Cosmos DB and Azure Synapse Analytics.

# Enable offline development
* <ins>The Azure Cosmos DB emulator</ins is a great tool for common Dev+Test workflows that developers may need to implement on their local machine.
    
* Handle connection errors - Built-in retry    
    
# Implement threading and parallelism
* While the SDK implements thread-safe types and some degrees of parallelism, there are best practices that you can implement in your application code to ensure that the SDK has the best performance it can possibly have in your workload.
* Avoid resource-related timeouts - occur due to high CPU or port utilization on client machines rather than a service-side issue. So scale-out.
* Use async/await in .NET -  series of Task-based features to asynchronously invoke SDK client methods. 
* Use built-in iterators instead of LINQ methods - LINQ methods such as ToList will eagerly and synchronously drain a query while blocking any other calls from executing. 
    1. For example, this invocation of ToList() will block all other calls and potentially retrieve a large set of data: container.GetItemLinqQueryable<T>().Where(i => i.categoryId == 2)   .ToList<T>();
    2. The SDK includes methods such as ToFeedIterator<T> that asynchronously retrieves the results of a query without blocking other calls. container.GetItemLinqQueryable<T>().Where(i => i.categoryId == 2).ToFeedIterator<T>();
    3. Configure max concurrency, parallelism, and buffered item count - When issuing a query from the SDK, the QueryRequestOptions includes a set of properties to tune a query's performance.
        1. Max item count - All query results are returned as "pages" of results. the number of items you would like to return in each "page". Default is 100. set -1 to set a dynamic page size.
        2. Max concurrency - the number of concurrent operations ran client side during parallel query execution. If set to 1, parallelism is effectively disabled. If set to -1, the SDK manages this setting. Ideally, you would set this value to the number of physical partitions for your container.
        3. Max buffered item count - the maximum number of items that are buffered client-side during a parallel query execution. If set to -1, the SDK manages this setting. The ideal value for this setting will largely depend on the characteristics of your client machine.
